{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_stock_variable_name(name, prefix=\"bert\"):\n",
    "    name = name.split(\":\")[0]\n",
    "    ns   = name.split(\"/\")\n",
    "    pns  = prefix.split(\"/\")\n",
    "#     print(\"rand\" , name, ns, pns)\n",
    "    if ns[:len(pns)] != pns:\n",
    "        return None\n",
    "\n",
    "    name = \"/\".join([\"bert\"] + ns[len(pns):])\n",
    "    ns   = name.split(\"/\")\n",
    "\n",
    "    if ns[1] not in [\"encoder\", \"embeddings\"]:\n",
    "        return None\n",
    "    if ns[1] == \"embeddings\":\n",
    "        if ns[2] == \"LayerNorm\":\n",
    "            return name\n",
    "        else:\n",
    "            return \"/\".join(ns[:-1])\n",
    "    if ns[1] == \"encoder\":\n",
    "        if ns[3] == \"intermediate\":\n",
    "            return \"/\".join(ns[:4] + [\"dense\"] + ns[4:])\n",
    "        else:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def map_to_stock_variable_name_v2(name, prefix=\"bert\"):\n",
    "    name = name.split(\":\")[0].replace(\"embeddings_1\", \"embeddings\")\n",
    "    return name\n",
    "\n",
    "def load_stock_weights(bert, ckpt_file):\n",
    "    \n",
    "    ckpt_reader = tf.train.load_checkpoint(ckpt_file)\n",
    "\n",
    "    bert_prefix = bert.weights[0].name.split(\"/\")[0]\n",
    "    print(bert_prefix)\n",
    "    weights = []\n",
    "    for idx, weight in enumerate(bert.weights):\n",
    "        print(idx, weight.name)\n",
    "        stock_name = map_to_stock_variable_name_v2(weight.name, bert_prefix)\n",
    "        \n",
    "        if ckpt_reader.has_tensor(stock_name):\n",
    "            \n",
    "            value = ckpt_reader.get_tensor(stock_name)\n",
    "#             print(\"stock_name\" , stock_name, \"value\", value)\n",
    "            weights.append(value)\n",
    "            \n",
    "        else:\n",
    "#             print(\"stock_name\" , stock_name)\n",
    "            print(\"loader: No value for:[{}], i.e.:[{}] in:[{}]\".format(weight.name, stock_name, ckpt_file))\n",
    "            # raise ValueError(\"No value for:[{}], i.e.:[{}] in:[{}]\".format(weight.name, stock_name, ckpt_file))\n",
    "            weights.append(weight.value())\n",
    "\n",
    "    bert.set_weights(weights)\n",
    "    print(\"Done loading {} BERT weights from: {} into {} (prefix:{})\".format(\n",
    "        len(weights), ckpt_file, bert, bert_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_config.json                     bert_model.ckpt.meta\r\n",
      "bert_model.ckpt.data-00000-of-00001  vocab.txt\r\n",
      "bert_model.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "ls /Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization\n",
    "\n",
    "class InputFeatures(object):\n",
    "\t\"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "\tdef __init__(self, input_ids, input_mask, segment_ids, label_ids,):\n",
    "\t\tself.input_ids = input_ids\n",
    "\t\tself.input_mask = input_mask\n",
    "\t\tself.segment_ids = segment_ids\n",
    "\t\tself.label_ids = label_ids\n",
    "\t\t#self.label_mask = label_mask\n",
    "\n",
    "#### Load labels mapping\n",
    "tokenizer_file_path = \"/Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/vocab.txt\"\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=tokenizer_file_path, do_lower_case=False)\n",
    "        \n",
    "def convert_single_example(example):\n",
    "    textlist = example.split(' ')\n",
    "    tokens = []\n",
    "    label_ids = [0]\n",
    "    for i, word in enumerate(textlist):\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokens.extend(token)\n",
    "    # tokens = tokenizer.tokenize(example.text)\n",
    "    if len(tokens) >= max_seq_length - 1:\n",
    "        tokens = tokens[0:(max_seq_length - 2)]\n",
    "    ntokens = []\n",
    "    segment_ids = []\n",
    "    ntokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    # append(\"O\") or append(\"[CLS]\") not sure!\n",
    "    label_ids.append(label_map[\"[CLS]\"])\n",
    "    for i, token in enumerate(tokens):\n",
    "        ntokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    ntokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "    # append(\"O\") or append(\"[SEP]\") not sure!\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "    #label_mask = [1] * len(input_ids)\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "        # we don't concerned about it!\n",
    "        ntokens.append(\"**NULL**\")\n",
    "        #label_mask.append(0)\n",
    "    # print(len(input_ids))\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "    #assert len(label_mask) == max_seq_length\n",
    "\n",
    "    feature = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_ids=label_ids,\n",
    "        #label_mask = label_mask\n",
    "    )\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\",\" , \".\", \"?\", \"O\" , \"X\",\"[CLS]\",\"[SEP]\"]\n",
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list,1):\n",
    "    label_map[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = convert_single_example(\"xx ans naval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import modeling as modeling\n",
    "from tensorflow import keras\n",
    "\n",
    "max_seq_len = 128\n",
    "\n",
    "# allow gpu growth\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)\n",
    "\n",
    "# bert config\n",
    "init_checkpoint = \"/Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "bert_config_file = \"/Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/bert_config.json\"\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "\n",
    "# fake input for initializing weights\n",
    "# input_ids = tf.Variable(tf.ones(shape=(1, 512), dtype=tf.int32))\n",
    "# input_ids      = tf.keras.layers.Input(shape=(max_seq_len), dtype='int32', name=\"input_ids\")\n",
    "input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
    "token_type_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"token_type_ids\")\n",
    "input_mask = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_mask\")\n",
    "bert = modeling.BertModel(bert_config, is_training=True)\n",
    "\n",
    "\n",
    "# print(\"Loading weights\")\n",
    "# bert.load_weights(init_checkpoint)\n",
    "# print(\"Weights loadad!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = bert(input_ids, input_mask=input_mask, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bert/Identity:0' shape=(None, 768) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.keras.layers.Dense(2)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask, token_type_ids], outputs=output)\n",
    "model.build(input_shape=[(None, max_seq_len),\n",
    "                                 (None, max_seq_len), (None, max_seq_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/Identity:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                (None, 768)          177853440   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1538        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 177,854,978\n",
      "Trainable params: 177,854,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "0 bert/embeddings/word_embeddings:0\n",
      "1 bert/embeddings_1/token_type_embeddings:0\n",
      "2 bert/embeddings_1/position_embeddings:0\n",
      "3 bert/embeddings_1/LayerNorm/gamma:0\n",
      "4 bert/embeddings_1/LayerNorm/beta:0\n",
      "5 bert/encoder/layer_0/attention/self/query/kernel:0\n",
      "6 bert/encoder/layer_0/attention/self/query/bias:0\n",
      "7 bert/encoder/layer_0/attention/self/key/kernel:0\n",
      "8 bert/encoder/layer_0/attention/self/key/bias:0\n",
      "9 bert/encoder/layer_0/attention/self/value/kernel:0\n",
      "10 bert/encoder/layer_0/attention/self/value/bias:0\n",
      "11 bert/encoder/layer_1/attention/self/query/kernel:0\n",
      "12 bert/encoder/layer_1/attention/self/query/bias:0\n",
      "13 bert/encoder/layer_1/attention/self/key/kernel:0\n",
      "14 bert/encoder/layer_1/attention/self/key/bias:0\n",
      "15 bert/encoder/layer_1/attention/self/value/kernel:0\n",
      "16 bert/encoder/layer_1/attention/self/value/bias:0\n",
      "17 bert/encoder/layer_2/attention/self/query/kernel:0\n",
      "18 bert/encoder/layer_2/attention/self/query/bias:0\n",
      "19 bert/encoder/layer_2/attention/self/key/kernel:0\n",
      "20 bert/encoder/layer_2/attention/self/key/bias:0\n",
      "21 bert/encoder/layer_2/attention/self/value/kernel:0\n",
      "22 bert/encoder/layer_2/attention/self/value/bias:0\n",
      "23 bert/encoder/layer_3/attention/self/query/kernel:0\n",
      "24 bert/encoder/layer_3/attention/self/query/bias:0\n",
      "25 bert/encoder/layer_3/attention/self/key/kernel:0\n",
      "26 bert/encoder/layer_3/attention/self/key/bias:0\n",
      "27 bert/encoder/layer_3/attention/self/value/kernel:0\n",
      "28 bert/encoder/layer_3/attention/self/value/bias:0\n",
      "29 bert/encoder/layer_4/attention/self/query/kernel:0\n",
      "30 bert/encoder/layer_4/attention/self/query/bias:0\n",
      "31 bert/encoder/layer_4/attention/self/key/kernel:0\n",
      "32 bert/encoder/layer_4/attention/self/key/bias:0\n",
      "33 bert/encoder/layer_4/attention/self/value/kernel:0\n",
      "34 bert/encoder/layer_4/attention/self/value/bias:0\n",
      "35 bert/encoder/layer_5/attention/self/query/kernel:0\n",
      "36 bert/encoder/layer_5/attention/self/query/bias:0\n",
      "37 bert/encoder/layer_5/attention/self/key/kernel:0\n",
      "38 bert/encoder/layer_5/attention/self/key/bias:0\n",
      "39 bert/encoder/layer_5/attention/self/value/kernel:0\n",
      "40 bert/encoder/layer_5/attention/self/value/bias:0\n",
      "41 bert/encoder/layer_6/attention/self/query/kernel:0\n",
      "42 bert/encoder/layer_6/attention/self/query/bias:0\n",
      "43 bert/encoder/layer_6/attention/self/key/kernel:0\n",
      "44 bert/encoder/layer_6/attention/self/key/bias:0\n",
      "45 bert/encoder/layer_6/attention/self/value/kernel:0\n",
      "46 bert/encoder/layer_6/attention/self/value/bias:0\n",
      "47 bert/encoder/layer_7/attention/self/query/kernel:0\n",
      "48 bert/encoder/layer_7/attention/self/query/bias:0\n",
      "49 bert/encoder/layer_7/attention/self/key/kernel:0\n",
      "50 bert/encoder/layer_7/attention/self/key/bias:0\n",
      "51 bert/encoder/layer_7/attention/self/value/kernel:0\n",
      "52 bert/encoder/layer_7/attention/self/value/bias:0\n",
      "53 bert/encoder/layer_8/attention/self/query/kernel:0\n",
      "54 bert/encoder/layer_8/attention/self/query/bias:0\n",
      "55 bert/encoder/layer_8/attention/self/key/kernel:0\n",
      "56 bert/encoder/layer_8/attention/self/key/bias:0\n",
      "57 bert/encoder/layer_8/attention/self/value/kernel:0\n",
      "58 bert/encoder/layer_8/attention/self/value/bias:0\n",
      "59 bert/encoder/layer_9/attention/self/query/kernel:0\n",
      "60 bert/encoder/layer_9/attention/self/query/bias:0\n",
      "61 bert/encoder/layer_9/attention/self/key/kernel:0\n",
      "62 bert/encoder/layer_9/attention/self/key/bias:0\n",
      "63 bert/encoder/layer_9/attention/self/value/kernel:0\n",
      "64 bert/encoder/layer_9/attention/self/value/bias:0\n",
      "65 bert/encoder/layer_10/attention/self/query/kernel:0\n",
      "66 bert/encoder/layer_10/attention/self/query/bias:0\n",
      "67 bert/encoder/layer_10/attention/self/key/kernel:0\n",
      "68 bert/encoder/layer_10/attention/self/key/bias:0\n",
      "69 bert/encoder/layer_10/attention/self/value/kernel:0\n",
      "70 bert/encoder/layer_10/attention/self/value/bias:0\n",
      "71 bert/encoder/layer_11/attention/self/query/kernel:0\n",
      "72 bert/encoder/layer_11/attention/self/query/bias:0\n",
      "73 bert/encoder/layer_11/attention/self/key/kernel:0\n",
      "74 bert/encoder/layer_11/attention/self/key/bias:0\n",
      "75 bert/encoder/layer_11/attention/self/value/kernel:0\n",
      "76 bert/encoder/layer_11/attention/self/value/bias:0\n",
      "77 bert/encoder/layer_0/attention/output/dense/kernel:0\n",
      "78 bert/encoder/layer_0/attention/output/dense/bias:0\n",
      "79 bert/encoder/layer_1/attention/output/dense/kernel:0\n",
      "80 bert/encoder/layer_1/attention/output/dense/bias:0\n",
      "81 bert/encoder/layer_2/attention/output/dense/kernel:0\n",
      "82 bert/encoder/layer_2/attention/output/dense/bias:0\n",
      "83 bert/encoder/layer_3/attention/output/dense/kernel:0\n",
      "84 bert/encoder/layer_3/attention/output/dense/bias:0\n",
      "85 bert/encoder/layer_4/attention/output/dense/kernel:0\n",
      "86 bert/encoder/layer_4/attention/output/dense/bias:0\n",
      "87 bert/encoder/layer_5/attention/output/dense/kernel:0\n",
      "88 bert/encoder/layer_5/attention/output/dense/bias:0\n",
      "89 bert/encoder/layer_6/attention/output/dense/kernel:0\n",
      "90 bert/encoder/layer_6/attention/output/dense/bias:0\n",
      "91 bert/encoder/layer_7/attention/output/dense/kernel:0\n",
      "92 bert/encoder/layer_7/attention/output/dense/bias:0\n",
      "93 bert/encoder/layer_8/attention/output/dense/kernel:0\n",
      "94 bert/encoder/layer_8/attention/output/dense/bias:0\n",
      "95 bert/encoder/layer_9/attention/output/dense/kernel:0\n",
      "96 bert/encoder/layer_9/attention/output/dense/bias:0\n",
      "97 bert/encoder/layer_10/attention/output/dense/kernel:0\n",
      "98 bert/encoder/layer_10/attention/output/dense/bias:0\n",
      "99 bert/encoder/layer_11/attention/output/dense/kernel:0\n",
      "100 bert/encoder/layer_11/attention/output/dense/bias:0\n",
      "101 bert/encoder/layer_0/attention/output/LayerNorm/gamma:0\n",
      "102 bert/encoder/layer_0/attention/output/LayerNorm/beta:0\n",
      "103 bert/encoder/layer_1/attention/output/LayerNorm/gamma:0\n",
      "104 bert/encoder/layer_1/attention/output/LayerNorm/beta:0\n",
      "105 bert/encoder/layer_2/attention/output/LayerNorm/gamma:0\n",
      "106 bert/encoder/layer_2/attention/output/LayerNorm/beta:0\n",
      "107 bert/encoder/layer_3/attention/output/LayerNorm/gamma:0\n",
      "108 bert/encoder/layer_3/attention/output/LayerNorm/beta:0\n",
      "109 bert/encoder/layer_4/attention/output/LayerNorm/gamma:0\n",
      "110 bert/encoder/layer_4/attention/output/LayerNorm/beta:0\n",
      "111 bert/encoder/layer_5/attention/output/LayerNorm/gamma:0\n",
      "112 bert/encoder/layer_5/attention/output/LayerNorm/beta:0\n",
      "113 bert/encoder/layer_6/attention/output/LayerNorm/gamma:0\n",
      "114 bert/encoder/layer_6/attention/output/LayerNorm/beta:0\n",
      "115 bert/encoder/layer_7/attention/output/LayerNorm/gamma:0\n",
      "116 bert/encoder/layer_7/attention/output/LayerNorm/beta:0\n",
      "117 bert/encoder/layer_8/attention/output/LayerNorm/gamma:0\n",
      "118 bert/encoder/layer_8/attention/output/LayerNorm/beta:0\n",
      "119 bert/encoder/layer_9/attention/output/LayerNorm/gamma:0\n",
      "120 bert/encoder/layer_9/attention/output/LayerNorm/beta:0\n",
      "121 bert/encoder/layer_10/attention/output/LayerNorm/gamma:0\n",
      "122 bert/encoder/layer_10/attention/output/LayerNorm/beta:0\n",
      "123 bert/encoder/layer_11/attention/output/LayerNorm/gamma:0\n",
      "124 bert/encoder/layer_11/attention/output/LayerNorm/beta:0\n",
      "125 bert/encoder/layer_0/intermediate/dense/kernel:0\n",
      "126 bert/encoder/layer_0/intermediate/dense/bias:0\n",
      "127 bert/encoder/layer_1/intermediate/dense/kernel:0\n",
      "128 bert/encoder/layer_1/intermediate/dense/bias:0\n",
      "129 bert/encoder/layer_2/intermediate/dense/kernel:0\n",
      "130 bert/encoder/layer_2/intermediate/dense/bias:0\n",
      "131 bert/encoder/layer_3/intermediate/dense/kernel:0\n",
      "132 bert/encoder/layer_3/intermediate/dense/bias:0\n",
      "133 bert/encoder/layer_4/intermediate/dense/kernel:0\n",
      "134 bert/encoder/layer_4/intermediate/dense/bias:0\n",
      "135 bert/encoder/layer_5/intermediate/dense/kernel:0\n",
      "136 bert/encoder/layer_5/intermediate/dense/bias:0\n",
      "137 bert/encoder/layer_6/intermediate/dense/kernel:0\n",
      "138 bert/encoder/layer_6/intermediate/dense/bias:0\n",
      "139 bert/encoder/layer_7/intermediate/dense/kernel:0\n",
      "140 bert/encoder/layer_7/intermediate/dense/bias:0\n",
      "141 bert/encoder/layer_8/intermediate/dense/kernel:0\n",
      "142 bert/encoder/layer_8/intermediate/dense/bias:0\n",
      "143 bert/encoder/layer_9/intermediate/dense/kernel:0\n",
      "144 bert/encoder/layer_9/intermediate/dense/bias:0\n",
      "145 bert/encoder/layer_10/intermediate/dense/kernel:0\n",
      "146 bert/encoder/layer_10/intermediate/dense/bias:0\n",
      "147 bert/encoder/layer_11/intermediate/dense/kernel:0\n",
      "148 bert/encoder/layer_11/intermediate/dense/bias:0\n",
      "149 bert/encoder/layer_0/output/dense/kernel:0\n",
      "150 bert/encoder/layer_0/output/dense/bias:0\n",
      "151 bert/encoder/layer_1/output/dense/kernel:0\n",
      "152 bert/encoder/layer_1/output/dense/bias:0\n",
      "153 bert/encoder/layer_2/output/dense/kernel:0\n",
      "154 bert/encoder/layer_2/output/dense/bias:0\n",
      "155 bert/encoder/layer_3/output/dense/kernel:0\n",
      "156 bert/encoder/layer_3/output/dense/bias:0\n",
      "157 bert/encoder/layer_4/output/dense/kernel:0\n",
      "158 bert/encoder/layer_4/output/dense/bias:0\n",
      "159 bert/encoder/layer_5/output/dense/kernel:0\n",
      "160 bert/encoder/layer_5/output/dense/bias:0\n",
      "161 bert/encoder/layer_6/output/dense/kernel:0\n",
      "162 bert/encoder/layer_6/output/dense/bias:0\n",
      "163 bert/encoder/layer_7/output/dense/kernel:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 bert/encoder/layer_7/output/dense/bias:0\n",
      "165 bert/encoder/layer_8/output/dense/kernel:0\n",
      "166 bert/encoder/layer_8/output/dense/bias:0\n",
      "167 bert/encoder/layer_9/output/dense/kernel:0\n",
      "168 bert/encoder/layer_9/output/dense/bias:0\n",
      "169 bert/encoder/layer_10/output/dense/kernel:0\n",
      "170 bert/encoder/layer_10/output/dense/bias:0\n",
      "171 bert/encoder/layer_11/output/dense/kernel:0\n",
      "172 bert/encoder/layer_11/output/dense/bias:0\n",
      "173 bert/encoder/layer_0/output/LayerNorm/gamma:0\n",
      "174 bert/encoder/layer_0/output/LayerNorm/beta:0\n",
      "175 bert/encoder/layer_1/output/LayerNorm/gamma:0\n",
      "176 bert/encoder/layer_1/output/LayerNorm/beta:0\n",
      "177 bert/encoder/layer_2/output/LayerNorm/gamma:0\n",
      "178 bert/encoder/layer_2/output/LayerNorm/beta:0\n",
      "179 bert/encoder/layer_3/output/LayerNorm/gamma:0\n",
      "180 bert/encoder/layer_3/output/LayerNorm/beta:0\n",
      "181 bert/encoder/layer_4/output/LayerNorm/gamma:0\n",
      "182 bert/encoder/layer_4/output/LayerNorm/beta:0\n",
      "183 bert/encoder/layer_5/output/LayerNorm/gamma:0\n",
      "184 bert/encoder/layer_5/output/LayerNorm/beta:0\n",
      "185 bert/encoder/layer_6/output/LayerNorm/gamma:0\n",
      "186 bert/encoder/layer_6/output/LayerNorm/beta:0\n",
      "187 bert/encoder/layer_7/output/LayerNorm/gamma:0\n",
      "188 bert/encoder/layer_7/output/LayerNorm/beta:0\n",
      "189 bert/encoder/layer_8/output/LayerNorm/gamma:0\n",
      "190 bert/encoder/layer_8/output/LayerNorm/beta:0\n",
      "191 bert/encoder/layer_9/output/LayerNorm/gamma:0\n",
      "192 bert/encoder/layer_9/output/LayerNorm/beta:0\n",
      "193 bert/encoder/layer_10/output/LayerNorm/gamma:0\n",
      "194 bert/encoder/layer_10/output/LayerNorm/beta:0\n",
      "195 bert/encoder/layer_11/output/LayerNorm/gamma:0\n",
      "196 bert/encoder/layer_11/output/LayerNorm/beta:0\n",
      "197 bert/pooler/dense/kernel:0\n",
      "198 bert/pooler/dense/bias:0\n",
      "199 dense/kernel:0\n",
      "loader: No value for:[dense/kernel:0], i.e.:[dense/kernel] in:[/Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "200 dense/bias:0\n",
      "loader: No value for:[dense/bias:0], i.e.:[dense/bias] in:[/Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n",
      "Done loading 201 BERT weights from: /Users/naval/Desktop/Naval/CBM/BERT-NER-master/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt into <tensorflow.python.keras.engine.training.Model object at 0x15163f438> (prefix:bert)\n"
     ]
    }
   ],
   "source": [
    "load_stock_weights(model, init_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                (None, 768)          177853440   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1538        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 177,854,978\n",
      "Trainable params: 177,854,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x157c35710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert.segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 76294, 11744, 25922,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(convert.input_ids).reshape(1,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict([np.array(convert.input_ids).reshape(1,128), np.array(convert.input_mask).reshape(1,128), np.array(convert.segment_ids).reshape(1,128)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31052852, 0.6488204 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20167862, 0.30923742]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_names = ['bert/embeddings/word_embeddings/embeddings:0',\n",
    " 'bert/embeddings/token_type_embeddings/embeddings:0',\n",
    " 'bert/embeddings/position_embeddings/embeddings:0',\n",
    " 'bert/embeddings/LayerNorm/gamma:0',\n",
    " 'bert/embeddings/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_0/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_0/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_0/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_0/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_0/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_0/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_0/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_0/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_0/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_0/intermediate/bias:0',\n",
    " 'bert/encoder/layer_0/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_0/output/dense/bias:0',\n",
    " 'bert/encoder/layer_0/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_0/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_1/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_1/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_1/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_1/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_1/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_1/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_1/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_1/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_1/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_1/intermediate/bias:0',\n",
    " 'bert/encoder/layer_1/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_1/output/dense/bias:0',\n",
    " 'bert/encoder/layer_1/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_1/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_2/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_2/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_2/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_2/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_2/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_2/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_2/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_2/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_2/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_2/intermediate/bias:0',\n",
    " 'bert/encoder/layer_2/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_2/output/dense/bias:0',\n",
    " 'bert/encoder/layer_2/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_2/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_3/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_3/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_3/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_3/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_3/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_3/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_3/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_3/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_3/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_3/intermediate/bias:0',\n",
    " 'bert/encoder/layer_3/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_3/output/dense/bias:0',\n",
    " 'bert/encoder/layer_3/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_3/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_4/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_4/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_4/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_4/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_4/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_4/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_4/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_4/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_4/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_4/intermediate/bias:0',\n",
    " 'bert/encoder/layer_4/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_4/output/dense/bias:0',\n",
    " 'bert/encoder/layer_4/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_4/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_5/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_5/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_5/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_5/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_5/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_5/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_5/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_5/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_5/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_5/intermediate/bias:0',\n",
    " 'bert/encoder/layer_5/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_5/output/dense/bias:0',\n",
    " 'bert/encoder/layer_5/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_5/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_6/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_6/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_6/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_6/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_6/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_6/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_6/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_6/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_6/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_6/intermediate/bias:0',\n",
    " 'bert/encoder/layer_6/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_6/output/dense/bias:0',\n",
    " 'bert/encoder/layer_6/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_6/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_7/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_7/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_7/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_7/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_7/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_7/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_7/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_7/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_7/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_7/intermediate/bias:0',\n",
    " 'bert/encoder/layer_7/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_7/output/dense/bias:0',\n",
    " 'bert/encoder/layer_7/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_7/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_8/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_8/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_8/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_8/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_8/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_8/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_8/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_8/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_8/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_8/intermediate/bias:0',\n",
    " 'bert/encoder/layer_8/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_8/output/dense/bias:0',\n",
    " 'bert/encoder/layer_8/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_8/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_9/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_9/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_9/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_9/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_9/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_9/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_9/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_9/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_9/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_9/intermediate/bias:0',\n",
    " 'bert/encoder/layer_9/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_9/output/dense/bias:0',\n",
    " 'bert/encoder/layer_9/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_9/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_10/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_10/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_10/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_10/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_10/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_10/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_10/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_10/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_10/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_10/intermediate/bias:0',\n",
    " 'bert/encoder/layer_10/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_10/output/dense/bias:0',\n",
    " 'bert/encoder/layer_10/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_10/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_11/attention/self/query/kernel:0',\n",
    " 'bert/encoder/layer_11/attention/self/query/bias:0',\n",
    " 'bert/encoder/layer_11/attention/self/key/kernel:0',\n",
    " 'bert/encoder/layer_11/attention/self/key/bias:0',\n",
    " 'bert/encoder/layer_11/attention/self/value/kernel:0',\n",
    " 'bert/encoder/layer_11/attention/self/value/bias:0',\n",
    " 'bert/encoder/layer_11/attention/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_11/attention/output/dense/bias:0',\n",
    " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0',\n",
    " 'bert/encoder/layer_11/intermediate/kernel:0',\n",
    " 'bert/encoder/layer_11/intermediate/bias:0',\n",
    " 'bert/encoder/layer_11/output/dense/kernel:0',\n",
    " 'bert/encoder/layer_11/output/dense/bias:0',\n",
    " 'bert/encoder/layer_11/output/LayerNorm/gamma:0',\n",
    " 'bert/encoder/layer_11/output/LayerNorm/beta:0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for idx, (actual, curr) in enumerate(zip(actual_names, bert.weights)):\n",
    "# #     if actual != curr.name:\n",
    "#     if not map_to_stock_variable_name(actual) == map_to_stock_variable_name_v2(curr.name):\n",
    "#         print (idx, actual, map_to_stock_variable_name(actual) , map_to_stock_variable_name_v2(curr.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for idx, each in enumerate(bert.weights):\n",
    "#     print(idx, each.name, map_to_stock_variable_name(each.name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.0]",
   "language": "python",
   "name": "conda-env-tensorflow-2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
